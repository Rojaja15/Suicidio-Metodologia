# Analisis multivariado

# Limpieza

## Librerias

```{r}

library(tidyverse)
library(fastDummies)
library(FactoMineR)
library(factoextra)
library(cluster)
library(dendextend)
library(caret)
library(reticulate)
library(htmltools)
library(IRdisplay)
library(readxl)
library(dplyr)
library(ggplot2)
library(tidyr)
library(lubridate)
library(psych)
library(ggcorrplot)
library(janitor)
library(summarytools)
library(broom)
library(readxl)
library(cowplot)

```

## Funciones

```{r}

inercia_intraclase <- function(datos, grupos) {
  # Combina los datos y los grupos en una sola tabla
  tabla <- cbind(datos, grupos)

  # Calcula los centroides (puntos medios) de cada grupo
  centroides <- lapply(unique(grupos), function(id_grupo) {
    subconjunto <- subset(tabla, grupos == id_grupo)
    apply(subconjunto[, 1:(ncol(subconjunto)-1)], 2, mean)
  })

  # Calcula la suma de las distancias al cuadrado de cada punto a su centroide
  suma_cuadrados <- sum(sapply(unique(grupos), function(id_grupo) {
    subconjunto <- subset(tabla, grupos == id_grupo, select = -grupos)
    centroide_actual <- centroides[[id_grupo]]

    # Resta el centroide a cada punto y calcula la suma de cuadrados
    sum(sweep(subconjunto, 2, centroide_actual, "-")^2)
  }))

  return(suma_cuadrados)
}

```

```{r}

options(tibble.width = Inf)

```


# Analisis multivariado


```{r}
df_escalado <- read.csv("Data/df_escalado.csv")
```


```{r}

cor_matrix = cor(numeric_vars, use = "pairwise.complete.obs")

ggcorrplot(cor_matrix,
           hc.order = T,
           type = "lower",
           lab = F,
           tl.cex = 6,   # tamaño del texto
           tl.srt = 45,  # rotar etiquetas
           outline.col = "white"
           ) +
  labs(title = "Matrix de correlaciones") +
  theme(plot.title = element_text(hjust = 0.5))

```

Funcion para analisis bivariado

Realiza boxplots, la prubea t o anova + tukey segun corresponda, y si no hay suficiente para correr salta   el analisis dando un mensaje que no hay sufiucientes valores

```{r}

vars_cat = names(select_if(df, \(x) is.character(x) | is.factor(x)))
vars_num = names(select_if(df, is.numeric))

```

```{r}

analisis_bivariado <- function(data, var_cat, var_num) {
  cat("\n=============================================\n")
  cat("Categórica:", var_cat, "| Numérica:", var_num, "\n")

  temp <- data %>%
    select(all_of(c(var_cat, var_num))) %>%
    drop_na()

  # Si no hay suficientes datos o niveles, saltar

  if (nrow(temp) < 5 | length(unique(temp[[var_cat]])) < 2) {
    cat("No hay suficientes datos o niveles para analizar.\n")
    return(NULL)
  }


  # Contar observaciones por grupo

  conteo <- temp %>% count(.data[[var_cat]])
  cat("Tamaño por grupo:\n")
  print(conteo)

  # Si algún grupo tiene < 2 observaciones → saltar

  if (any(conteo$n < 2)) {
    cat("Al menos un grupo tiene menos de 2 observaciones. Se omite este análisis.\n")
    return(NULL)
  }

  n_grupos <- n_distinct(temp[[var_cat]])

  # Boxplot

  p <- ggplot(temp, aes_string(x = var_cat, y = var_num, fill = var_cat)) +
    geom_boxplot(alpha = 0.7, color = "black") +
    theme_minimal() +
    labs(title = paste("Distribución de", var_num, "según", var_cat),
         x = var_cat, y = var_num) +
    theme(legend.position = "none")
  print(p)

  # Pruebas estadísticas

  if (n_grupos == 2) {
    prueba <- t.test(temp[[var_num]] ~ temp[[var_cat]])
    cat("\n--- PRUEBA t DE STUDENT ---\n")
    print(prueba)
    if (prueba$p.value < 0.05) {
      cat("Diferencias significativas (p <", round(prueba$p.value, 4), ")\n")
    } else {
      cat("No hay diferencias significativas (p =", round(prueba$p.value, 4), ")\n")
    }

  } else if (n_grupos > 2) {
    modelo <- aov(temp[[var_num]] ~ temp[[var_cat]])
    resumen <- summary(modelo)
    cat("\n--- ANOVA ---\n")
    print(resumen)

    pval <- resumen[[1]][["Pr(>F)"]][1]
    if (pval < 0.05) {
      cat("Diferencias significativas entre grupos (p <", round(pval, 4), ")\n")
      cat("\n--- PRUEBA POST-HOC (Tukey) ---\n")
      print(TukeyHSD(modelo))
    } else {
      cat("No hay diferencias significativas (p =", round(pval, 4), ")\n")
    }
  }
}

```

**Ciclo** for para que itere y prueba la funcion anterior con variables categoricas y numericas

```{r}

for (cat_var in vars_cat) {
  for (num_var in vars_num) {
    analisis_bivariado(df, cat_var, num_var)
  }
}

```

## ACP

### Modelo con todas las variables

```{r}

modelo_ACP <- PCA(df_escalado,   #se corre el modelo con PCA
              scale.unit = FALSE,    #Escalar los datos
              ncp = 3,           #Número de componentes principales
              graph = FALSE)

```

### Plano principal (individuos)

```{r}

fviz_pca_ind(X = modelo_ACP, pointsize = 3,
             pointshape = 21,
             axes = c(1,3), #Primeras dos componentes
             select.ind = list(cos2 = 0.1),
             alpha.ind = 0.8,
             fill = "#FF8C32", repel = TRUE)

```

### Circulo de correlaciones (variables)

```{r}

plot(x = modelo_ACP, axes = c(1, 2), # primeras dos componentes
     choix = "var", col.var = "#2E9FDF",
     select.ind = list(cos2 = 0.1),
     new.plot = TRUE)

```

### Biplot

```{r, fig.width= 25}

fviz_pca_biplot(modelo_ACP,
                pointsize = 4,
                axes = c(1,2), #Primeras dos componentes
                col.var = "#2E9FDF", #Color de la variable
                col.ind = "#FF8C32", #Color de los individuos
                select.var = list(cos2 = 0.1), #Extracción de variables mal representadas
                select.ind = list(cos2 = 0.1)) #Extracción de individuos mal representados

```

### Modelo con solo variables numericas y EIS

```{r}

# 2. Vector de variables con los NOMBRES CORRECTOS
variables_seleccionadas <- c(
  'salud_fisica', 'maltrato_emocional', 'castigo_fisico', 'abuso_sexual',
  'ocultar_emociones', 'dificultad_pedir_ayuda', 'guarda_sentimientos',
  'sin_motivacion', 'preocupado', 'sin_proposito', 'no_reconocer_logros',
  'incapaz_solucionar', 'intento_autolesion', 'plan_autolesion', 'autolesion_fisica',
  'conduccion_temeraria', 'soledad', 'conflicto_familiar', 'dificultad_economica',
  'exigencia_academica_laboral', 'descontrol_drogas', 'abuso_alcohol',
  'descontrol_enojo', 'edad', 'sesiones_cumplidas', "EIS_Roberts",
  'EIS_alto',
  'EIS_medio',
  'EIS_bajo'
)

# Crear el nuevo dataframe
df_seleccionado <- df_escalado %>%
  select(all_of(variables_seleccionadas))


# 3. Realizar el Análisis de Componentes Principales (ACP)
resultado_acp <- prcomp(df_seleccionado, scale. = FALSE)


# 4. Crear el Círculo de Correlaciones
grafico_correlaciones <- fviz_pca_var(
  resultado_acp,
  axes = c(1, 2),
  col.var = "contrib",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
  repel = TRUE,
  title = "Círculo de Correlaciones ACP"
)

# 5. Mostrar el gráfico
print(grafico_correlaciones)

```

```{r}

# 4. Crear el Círculo de Correlaciones
grafico_correlaciones <- fviz_pca_var(
  resultado_acp,
  axes = c(1, 3),
  col.var = "contrib",
  gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
  repel = TRUE,
  title = "Círculo de Correlaciones ACP"
)

# 5. Mostrar el gráfico
print(grafico_correlaciones)

```

```{r}

# 3. Crear el biplot con los individuos en color naranja
grafico_biplot_naranja <- fviz_pca_biplot(
  resultado_acp,
  geom.ind = "point",
  col.ind = "tomato",  # <-- Aquí especificamos el color para los individuos
  alpha.ind = 0.5,     # Mantenemos la transparencia para ver la densidad
  repel = TRUE,        # Evita que las etiquetas de las variables se solapen
  title = "Biplot ACP (Individuos y Variables)"
)

# 4. Mostrar el gráfico
print(grafico_biplot_naranja)

```

```{r}

# 3. Crear el biplot con los individuos en color naranja
grafico_biplot_naranja <- fviz_pca_biplot(
  resultado_acp,
  axes = c(1,3),
  geom.ind = "point",
  col.ind = "tomato",  # <-- Aquí especificamos el color para los individuos
  alpha.ind = 0.5,     # Mantenemos la transparencia para ver la densidad
  repel = TRUE,        # Evita que las etiquetas de las variables se solapen
  title = "Biplot ACP (Individuos y Variables)"
)

# 4. Mostrar el gráfico
print(grafico_biplot_naranja)

```

### Metodo del codo

```{r}

# Calcular y visualizar el número óptimo de clústeres con el método del codo
fviz_nbclust(df_escalado,
             FUNcluster = hcut,  # Especifica que usamos clustering jerárquico
             method = "wss") +   # "wss" es la inercia intraclase
  geom_vline(xintercept = 3, linetype = 2) + # Línea sugerida en el codo (ajusta este número)
  labs(subtitle = "Método del Codo (Elbow Method)")

```

### Silueta

```{r}

fviz_nbclust(df_escalado,
             FUNcluster = hcut,
             method = "silhouette") +
  labs(subtitle = "Análisis de Silueta para Clustering Jerárquico")

```


